---
title: "Sesión 2 — Evidencias, jerarquía y cierre crítico"
nav_order: 4
---

**Recomendación**: si lo necesitas, repasa el [Bloque 0 — Introducción general](bloque-0).

## BLOQUE 4. Educación basada en evidencias (EBE)

### 4.1. ¿Por qué hablar ahora de educación basada en evidencias?

Después de la primera sesión, ya contamos con varias ideas asentadas:

- La investigación educativa es compleja.
- Los resultados pueden ser frágiles.
- La transparencia y la calidad metodológica son condiciones necesarias.
- La evidencia no surge automáticamente de cualquier estudio.
En este punto aparece una pregunta natural:

Si la investigación tiene limitaciones,
¿cómo podemos usarla para mejorar la educación sin caer en el simplismo?

La educación basada en evidencias (EBE) surge precisamente como un intento de responder a esta pregunta.

### 4.2. ¿Qué es la educación basada en evidencias?

De forma general, la educación basada en evidencias puede entenderse como un enfoque que propone:

Tomar decisiones educativas informadas por la mejor evidencia científica disponible,
integrándola con el juicio profesional y el contexto educativo.

Esta definición ya nos adelanta tres componentes clave:

- Evidencia científica.
- Experiencia profesional.
- Contexto y valores educativos.
La EBE no propone sustituir al profesorado ni a los responsables educativos, sino:

- Apoyar las decisiones con conocimiento sistemático.
Reducir la dependencia de:

- Modas pedagógicas.
- Opiniones no contrastadas.
- Tradiciones no evaluadas.
### 4.3. Qué NO es la educación basada en evidencias

Para entender bien la EBE es casi más importante aclarar qué no es.

La EBE no es:

- Un recetario de “qué funciona siempre”.
- Una imposición tecnocrática.
- Un enfoque que ignore el contexto.
- Una negación del juicio profesional.
Idea clave

La educación basada en evidencias no elimina la complejidad educativa;
intenta gestionarla mejor.

### 4.4. Orígenes y transferencias del enfoque

El enfoque basado en evidencias tiene su origen en la medicina, donde:

- Las decisiones clínicas se apoyan en síntesis sistemáticas de investigación.
- Se evalúa la calidad de la evidencia disponible.
Este enfoque se trasladó progresivamente a:

- Psicología.
- Ciencias sociales.
- Educación.
En este proceso han tenido un papel clave organizaciones dedicadas a la síntesis rigurosa de evidencias, como la Cochrane Collaboration o la Campbell Collaboration, que han establecido estándares para:

- Revisiones sistemáticas.
- Evaluación de calidad.
- Transparencia metodológica.
### 4.5. De estudios individuales a cuerpos de evidencia

Un punto central de la EBE es el rechazo de una idea muy extendida:

- Un solo estudio no debería guiar decisiones educativas de amplio alcance.
En su lugar, la EBE enfatiza:

- La acumulación de evidencia.
- La consistencia de resultados.
- La replicación.
- La síntesis sistemática.
Esto conecta directamente con lo visto en la sesión 1:

Sin transparencia y calidad en los estudios primarios,

la evidencia sintetizada será débil o engañosa.

### 4.6. Tipos de evidencia en investigación educativa

En la práctica, la EBE distingue entre distintos niveles o tipos de evidencia:

Estudios primarios
Aportan información directa, pero están limitados por:

- Diseño.
- Muestra.
- Contexto.
Revisiones sistemáticas
Integran múltiples estudios de forma explícita y reproducible.

Meta-análisis
Permiten estimar:

- Tamaños de efecto promedio.
- Variabilidad entre estudios.
- Posibles moderadores.
- Revisiones paraguas (umbrella reviews)
- Sintetizan resultados de revisiones previas.
Idea clave

La fuerza de la evidencia no depende solo del diseño,
sino de la calidad y coherencia del conjunto de estudios.

### 4.7. Evidencia y toma de decisiones educativas

La EBE no propone una relación mecánica entre evidencia y acción.

Entre la evidencia disponible y una decisión educativa concreta intervienen:

- El contexto institucional.
- Los recursos disponibles.
- Las características del alumnado.
- Los valores educativos.
Por ello, la EBE plantea una relación informada, no automática:

- La evidencia orienta.
- El profesional decide.
- El contexto modula.
### 4.8. Primer punto de fricción: “¿y si la evidencia es limitada?”

Aquí aparece una tensión habitual en educación:

Muchas preguntas relevantes:

- No tienen evidencia sólida.
- O la evidencia es escasa, contradictoria o de baja calidad.
- La EBE no niega este problema. Al contrario, lo hace explícito.
Idea clave

Decir “no sabemos con suficiente certeza”
es una respuesta científicamente honesta.

Esto enlaza de nuevo con la metaciencia:

- Reconocer incertidumbre.
- Evitar afirmaciones sobredimensionadas.
- Priorizar la mejora progresiva del conocimiento.
### 4.9. Un matiz necesario: “evidencias” en el contexto español

El término educación basada en evidencias proviene de la traducción literal del inglés evidence-based education. Sin embargo, en el contexto español este término ha generado (y sigue generando) reticencias legítimas.

Uno de los motivos principales es el propio significado del término evidencia en español, que:

Puede interpretarse como algo:

- Incuestionable.
- Obvio.
- Cerrado al debate.
Y, por tanto, asociarse a una visión:

- Autoritaria.
- Tecnocrática.
- Prescriptiva de la educación.
Esta interpretación entra en conflicto con:

- La complejidad inherente de los procesos educativos.
- El papel central del juicio profesional.
- La diversidad de contextos y valores educativos.
#### 4.9.1. Del “evidence-based” al “research-informed”

Precisamente por estas razones, en el ámbito español (y también en otros contextos europeos) se ha propuesto reformular el enfoque, empleando expresiones como:

Educación informada por la investigación

Práctica educativa informada desde la investigación

Este desplazamiento terminológico no es cosmético, sino conceptual.

Como señalan trabajos como el de Ferrero (2020)

Ferrero 2020:

El enfoque evidence-based entendido como:

“lo que funciona”

aplicado de forma descendente (top-down)

puede conducir a:

- Simplificación excesiva.
- Pérdida de autonomía profesional.
- Reducción del papel del profesorado a mero aplicador de recetas.
Frente a ello, el enfoque research-informed practice propone:

- Integrar la evidencia científica como una fuente más de información.
Reconocer explícitamente:

- La experiencia profesional.
- El contexto educativo.
- Los valores y objetivos pedagógicos.
#### 4.9.2. Una aclaración clave para esta asignatura

En esta asignatura, cuando utilicemos el término:

educación basada en evidencias

lo haremos en un sentido amplio y no prescriptivo, entendiendo que:

La investigación informa la práctica,
pero no la sustituye ni la dicta.

O dicho de otro modo:

- La evidencia no decide.
- La evidencia orienta.
Las decisiones siguen siendo:

- Profesionales.
- Contextuales.
- Éticamente situadas.
#### 4.9.3. Conexión con la metaciencia

Esta aclaración conecta directamente con lo trabajado en la sesión 1:

Sin metaciencia:

- La evidencia puede ser frágil.
- Los resultados pueden estar inflados.
Sin una visión crítica de la EBE:

- La evidencia puede usarse como argumento de autoridad.
- La complejidad educativa puede quedar invisibilizada.
Por ello, metaciencia y educación informada desde la investigación no son enfoques independientes, sino complementarios.

#### 4.9.4. Idea clave para el aula

Idea clave 6

Hablar de educación basada en evidencias
no implica obedecer a la evidencia,
sino dialogar críticamente con ella.

Pregunta para el aula

¿Creéis que el rechazo al término “evidencias” se debe más a problemas del concepto o a cómo se ha usado en la práctica?

### 4.10. Idea clave del bloque

Idea clave 5

La educación basada en evidencias no busca certezas absolutas,
sino mejores decisiones bajo incertidumbre.

Pregunta para el aula

¿Os genera más confianza una propuesta educativa respaldada por muchos estudios modestos o por un solo estudio con resultados muy llamativos?

## BLOQUE 5. Jerarquía de evidencias y calidad

(Sesión 2 – núcleo central)

### 5.1. ¿Por qué necesitamos hablar de jerarquía de evidencias?

Una idea muy extendida, y problemática, en educación es la siguiente:

“Toda investigación aporta evidencia por igual.”

Desde una perspectiva metacientífica y de educación informada desde la investigación, esta afirmación no se sostiene.

Los estudios:

- No tienen todos la misma calidad.
- No controlan los mismos sesgos.
- No permiten el mismo grado de inferencia.
Por tanto, si queremos usar investigación para informar decisiones, necesitamos algún criterio para responder a preguntas como:

¿En qué resultados podemos confiar más?

¿Qué tipo de estudios aportan evidencia más sólida?

¿Cómo manejar resultados contradictorios?

Aquí entra en juego el concepto de jerarquía de evidencias.

### 5.2. Qué es (y qué no es) una jerarquía de evidencias

La jerarquía de evidencias es una herramienta conceptual, no una ley natural.

Su objetivo es:

Ordenar los tipos de estudios según:

- Su capacidad para controlar sesgos.
- Su potencial inferencial.
- La robustez de sus conclusiones.
Pero es importante aclarar desde el inicio:

#### Lo que NO es

❌ Una clasificación moral de “buenos” y “malos” estudios.

❌ Un ranking fijo e inamovible.

❌ Un argumento para descartar investigación cualitativa o contextual.

#### Lo que SÍ es

✔️ Un marco para ponderar resultados.

✔️ Una guía para interpretar la evidencia con prudencia.

✔️ Un apoyo para la toma de decisiones bajo incertidumbre.

### 5.3. Una jerarquía típica en investigación educativa

Aunque existen diferentes propuestas, de forma general en educación se suele considerar algo parecido a lo siguiente (de menor a mayor fuerza inferencial):

- Opinión experta, experiencia individual.
- Estudios descriptivos y correlacionales.
- Estudios cuasi-experimentales.
- Experimentos controlados (cuando son viables).
- Revisiones sistemáticas.
- Meta-análisis.
- Revisiones paraguas (umbrella reviews).
Idea clave

La jerarquía no elimina los niveles inferiores,
los sitúa en su lugar adecuado.

### 5.4. Diseño ≠ calidad: una distinción crucial

Uno de los errores más frecuentes, incluso en contextos académicos, es confundir:

Tipo de diseño
con

Calidad metodológica.

Por ejemplo:

Un experimento mal diseñado o mal reportado:

- Puede aportar poca evidencia.
Un estudio cuasi-experimental bien ejecutado y transparente:

- Puede ser altamente informativo.
Desde la metaciencia, esto es fundamental:

El diseño establece el potencial,
la calidad determina el valor real.

### 5.5. El papel de las revisiones sistemáticas y los meta-análisis

En la EBE, las revisiones sistemáticas y los meta-análisis ocupan un lugar central porque:

- Integran múltiples estudios.
- Reducen el peso de resultados idiosincráticos.
Permiten evaluar:

- Consistencia.
- Heterogeneidad.
- Posibles sesgos.
Pero (y esto es clave):

- Un meta-análisis no es automáticamente buena evidencia.
Su calidad depende de:

- La calidad de los estudios incluidos.
- Los criterios de inclusión/exclusión.
- La transparencia del proceso.
- El tratamiento del sesgo de publicación.
Aquí se conecta directamente con:

- Metaciencia.
- Autorregulación científica.
- Evaluación de calidad metodológica.
### 5.6. Evidencia fuerte, evidencia débil y evidencia inexistente

Un aporte importante de este bloque es enseñar a distinguir entre:

Evidencia fuerte

Resultados consistentes.

Estudios de calidad.

Síntesis transparentes.

Evidencia débil

Resultados inconsistentes.

Estudios pequeños o de baja calidad.

Alta heterogeneidad.

Ausencia de evidencia

Falta de estudios adecuados.

Preguntas todavía no investigadas.

Advertencia clave

Ausencia de evidencia no es evidencia de ausencia.

Esta distinción es crucial para:

- No sobredimensionar resultados.
- No descartar prematuramente intervenciones.
- Comunicar incertidumbre de forma honesta.
### 5.7. El riesgo del uso simplista de la jerarquía

Aquí introducimos el componente crítico de forma clara.

La jerarquía de evidencias puede ser mal utilizada cuando:

Se convierte en un argumento de autoridad:

- “Esto es evidencia de nivel X, luego hay que hacerlo”.
- Se ignora el contexto educativo.
- Se deslegitima automáticamente la experiencia profesional.
Esto enlaza con las críticas clásicas al enfoque what works y con la transición hacia enfoques research-informed.

### 5.8. Jerarquía de evidencias y toma de decisiones reales

En la práctica educativa, la jerarquía debe usarse como:

- Una brújula, no como un manual.
- Un apoyo para pensar, no para obedecer.
Una decisión educativa informada debería considerar:

- Qué dice la mejor evidencia disponible.
- Con qué grado de certeza.
- En qué contextos se ha obtenido.
- Qué límites presenta.
### 5.9. Idea clave del bloque

Idea clave 7

La jerarquía de evidencias no decide por nosotros,
pero nos ayuda a decidir mejor.

Pregunta para el aula

¿Creéis que una intervención con evidencia débil debería descartarse automáticamente, o puede tener sentido en determinados contextos?

## BLOQUE 6. Tensiones, límites y mirada crítica

(Cierre de la sesión 2 y de la asignatura)

### 6.1. Por qué es necesario un cierre crítico

Después de recorrer:

Metaciencia,

Autorregulación científica,

Educación informada desde la investigación,

Jerarquía de evidencias,

sería un error terminar con la sensación de que:

- La evidencia “resuelve” la educación.
- Investigar bien garantiza decisiones correctas.
- Los problemas educativos tienen soluciones técnicas claras.
Este bloque parte de una idea fundamental:

La buena ciencia no elimina los dilemas educativos;
los hace más visibles.

### 6.2. Límites estructurales de la evidencia en educación

La investigación educativa, incluso cuando se hace con rigor, se enfrenta a límites que no son solo metodológicos, sino epistemológicos y prácticos.

Algunos de los más relevantes:

Complejidad de los fenómenos educativos

Interacciones múltiples.

Procesos a largo plazo.

Resultados difícilmente aislables.

Dependencia del contexto

Lo que funciona en un contexto puede no hacerlo en otro.

Las condiciones de implementación son decisivas.

Limitaciones de las medidas

Muchos constructos educativos son indirectos.

La validez y fiabilidad no siempre están garantizadas.

Idea clave

En educación, la evidencia rara vez es definitiva;
suele ser provisional y contextual.

### 6.3. Evidencia, valores y decisiones educativas

Un punto crítico que a menudo se pasa por alto es que:

- La evidencia no contiene valores.
La investigación puede informar sobre:

- Qué efectos se observan.
- Con qué magnitud.
- En qué condiciones.
Pero no puede decidir:

- Qué objetivos educativos son prioritarios.
- Qué riesgos son aceptables.
- Qué valores deben guiar la acción educativa.
Por tanto, toda decisión educativa implica:

Evidencia empírica +

Juicio profesional +

Valores éticos y sociales.

Ignorar esta combinación conduce a:

- Tecnocratización de la educación.
- Uso indebido del lenguaje científico como argumento de autoridad.
### 6.4. El riesgo del “discurso de la evidencia”

Aquí aparece una de las críticas más relevantes al uso contemporáneo de la EBE.

El problema no es la evidencia en sí, sino:

- Cómo se usa el discurso de la evidencia.
Algunos riesgos habituales:

“La ciencia dice que…”

“Está demostrado que…”

“La evidencia muestra claramente que…”

Este tipo de afirmaciones:

- Simplifican resultados complejos.
- Ocultan incertidumbre.
- Invisibilizan desacuerdos en la literatura.
Desde una perspectiva metacientífica:

La evidencia mal comunicada puede ser tan problemática
como la ausencia de evidencia.

### 6.5. Responsabilidad del investigador/a en educación

Este bloque permite cerrar la asignatura con una idea central de responsabilidad científica.

Investigar en educación no es solo:

- Diseñar estudios.
- Analizar datos.
- Publicar resultados.
Implica también:

- Comunicar con honestidad.
- Reconocer límites.
- Evitar sobregeneralizaciones.
- Resistir presiones por simplificar mensajes.
Especialmente cuando:

- Los resultados pueden influir en políticas educativas.
- Se afectan prácticas docentes reales.
- Se legitiman decisiones institucionales.
### 6.6. ¿Qué aporta entonces la metaciencia y la EBE?

Llegados a este punto, conviene reformular la pregunta inicial del curso.

No se trata de:

“¿Funciona la educación basada en evidencias?”

Sino de algo más ajustado:

¿Cómo podemos investigar y usar la investigación
de forma más honesta, responsable y útil?

La metaciencia aporta:

- Diagnóstico de problemas.
- Evaluación empírica de prácticas científicas.
- Herramientas para mejorar la credibilidad.
La educación informada desde la investigación aporta:

- Un marco para usar la evidencia sin absolutizarla.
- Un lenguaje para hablar de incertidumbre.
- Un antídoto contra modas y soluciones milagro.
### 6.7. Cierre: construir una posición investigadora propia

Este curso no pretende que el alumnado:

- Adopte una postura concreta.
- Acepte un marco sin cuestionarlo.
- Se convierta automáticamente en investigador/a.
Pretende algo más modesto y más ambicioso a la vez:

Que cada estudiante empiece a construir
una posición investigadora propia, informada y crítica.

Esto implica:

- Saber cuándo confiar en la evidencia.
- Saber cuándo desconfiar de ella.
- Saber cuándo decir “no lo sabemos todavía”.
- Saber justificar decisiones en contextos de incertidumbre.
### 6.8. Idea clave final de la asignatura

Idea clave 8

Investigar bien en educación no consiste en eliminar la incertidumbre,
sino en hacerla explícita y gestionarla responsablemente.

Pregunta final para el aula

Si en el futuro realizáis un TFM, una tesis o un informe educativo,
¿qué os gustaría que alguien pudiera decir de vuestro trabajo como investigadores/as?
